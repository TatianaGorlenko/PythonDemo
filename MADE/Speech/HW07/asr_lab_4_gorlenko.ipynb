{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RcyxmRJGqlY"
   },
   "source": [
    "# Практика №4\n",
    "\n",
    "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDbO_rrWGq7j"
   },
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzJyomV1JaLp",
    "outputId": "a9ea5033-e3e5-437c-d7f7-a2c4ec61dbae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.11.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.11.0\n",
      "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11.0->torchaudio) (3.10.0.2)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu113\n",
      "    Uninstalling torch-1.10.0+cu113:\n",
      "      Successfully uninstalled torch-1.10.0+cu113\n",
      "Successfully installed torch-1.11.0 torchaudio-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TROAsHTXHWik",
    "outputId": "581c48b5-15cb-42d2-f6a6-14e447242b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
      "To: /content/lab4.zip\n",
      "100% 2.77M/2.77M [00:00<00:00, 75.5MB/s]\n",
      "/content/lab4\n"
     ]
    }
   ],
   "source": [
    "# !gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
    "\n",
    "# !unzip -q lab4.zip\n",
    "# !rm -rf lab4.zip sample_data\n",
    "# %cd lab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m4wcCtkIH2dn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from utils import TextTransform\n",
    "from utils import cer\n",
    "from utils import wer\n",
    "\n",
    "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
    "from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer\n",
    "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
    "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
    "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
    "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
    "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XHKuY8HnAC4M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  5 13:14:32 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   44C    P8    20W / 250W |      0MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NaESUZiHJgfN"
   },
   "outputs": [],
   "source": [
    "train_audio_transforms = torch.nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                              n_fft=400,\n",
    "                                                              hop_length=160,\n",
    "                                                              n_mels=80)\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "#-----------------------------TODO №2-----------------------------------\n",
    "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0])\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9OqoVLnrJsCV"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=80,\n",
    "        output_size=29,\n",
    "        conv2d_filters=32,\n",
    "        attention_dim=240,\n",
    "        attention_heads=8,\n",
    "        feedforward_dim=512,\n",
    "        num_layers=8,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.conv_in = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.conv_out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(conv2d_filters * (input_size // 4), attention_dim),\n",
    "            PositionalEncoding(attention_dim, 0.1),\n",
    "        )\n",
    "        positionwise_layer = PositionwiseFeedForward\n",
    "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
    "        self.encoder_layer = repeat(\n",
    "            num_layers,\n",
    "            lambda lnum: EncoderLayer(\n",
    "                attention_dim,\n",
    "                MultiHeadedAttention(\n",
    "                    attention_heads, attention_dim, dropout\n",
    "                ),\n",
    "                positionwise_layer(*positionwise_layer_args),\n",
    "                dropout,\n",
    "                normalize_before=True,\n",
    "                concat_after=False,\n",
    "            ),\n",
    "        )\n",
    "        self.after_norm = LayerNorm(attention_dim)\n",
    "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
    "\n",
    "    def forward(self, x, ilens):\n",
    "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
    "        x = self.conv_in(x)\n",
    "        b, c, t, f = x.size()\n",
    "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
    "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
    "        x, _ = self.encoder_layer(x, masks)\n",
    "        x = self.after_norm(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mhbOKdLLbXHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 29])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 800, 80)\n",
    "model = TransformerModel()\n",
    "output = model(x, [800, 90])\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d2p_8IjeKkqq"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
    "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        input_lengths = [x // 4 for x in input_lengths]\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if batch_idx % 500 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(spectrograms),\n",
    "                data_len,\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item(),\n",
    "                scheduler.get_last_lr()[0]))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, blank_label=28, decode=True):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
    "            \n",
    "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            input_lengths = [x // 4 for x in input_lengths]\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            if decode:\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths, blank_label)\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "    if decode:\n",
    "        avg_cer = sum(test_cer)/len(test_cer)\n",
    "        avg_wer = sum(test_wer)/len(test_wer)\n",
    "\n",
    "        print(f\"Test set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"Average loss: {test_loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MzEbtsB1LKsh"
   },
   "outputs": [],
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=2,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\", output_size=29):\n",
    "    \n",
    "    blank_label = output_size - 1\n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": output_size,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=output_size-1, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, blank_label=blank_label, decode=not(epoch % 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eExZLsUiLeXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=29, bias=True)\n",
      ")\n",
      "Num Model Parameters 10913277\n",
      "Sun Jun  5 10:38:13 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 4.716860\tLR: 0.000040\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.722835\tLR: 0.000096\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.798510\tLR: 0.000152\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.563412\tLR: 0.000208\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.325713\tLR: 0.000264\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.352825\tLR: 0.000320\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.1816\n",
      "\n",
      "Sun Jun  5 10:43:15 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 2.052702\tLR: 0.000360\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 2.226485\tLR: 0.000416\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 2.092316\tLR: 0.000472\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 2.180672\tLR: 0.000528\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 2.005398\tLR: 0.000584\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.980251\tLR: 0.000640\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.9253\n",
      "\n",
      "Sun Jun  5 10:48:17 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 2.048529\tLR: 0.000680\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.974017\tLR: 0.000736\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.970569\tLR: 0.000792\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.768127\tLR: 0.000848\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.899476\tLR: 0.000904\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.989148\tLR: 0.000961\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.5799\n",
      "\n",
      "Sun Jun  5 10:53:18 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.827129\tLR: 0.001000\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.605103\tLR: 0.000975\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.543583\tLR: 0.000950\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.777273\tLR: 0.000925\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.521476\tLR: 0.000900\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.556500\tLR: 0.000875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.2162\n",
      "\n",
      "Sun Jun  5 10:58:20 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 1.592907\tLR: 0.000857\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.331515\tLR: 0.000832\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.331811\tLR: 0.000807\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.186509\tLR: 0.000782\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.558169\tLR: 0.000757\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.214374\tLR: 0.000732\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.0321, Average CER: 0.260879 Average WER: 0.7244\n",
      "\n",
      "Sun Jun  5 11:07:24 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 1.098341\tLR: 0.000714\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 1.370643\tLR: 0.000689\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.285419\tLR: 0.000664\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 1.363083\tLR: 0.000639\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 1.240280\tLR: 0.000614\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 1.142410\tLR: 0.000589\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.9144\n",
      "\n",
      "Sun Jun  5 11:12:25 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 1.302032\tLR: 0.000571\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 1.378639\tLR: 0.000546\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.275205\tLR: 0.000521\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.914153\tLR: 0.000496\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 1.149467\tLR: 0.000471\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 1.182419\tLR: 0.000446\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.8220\n",
      "\n",
      "Sun Jun  5 11:17:27 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.991411\tLR: 0.000428\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 1.161985\tLR: 0.000403\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.242013\tLR: 0.000378\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.978811\tLR: 0.000353\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 1.038785\tLR: 0.000328\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 1.119855\tLR: 0.000303\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.7522\n",
      "\n",
      "Sun Jun  5 11:22:28 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.936681\tLR: 0.000286\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.955497\tLR: 0.000261\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.992844\tLR: 0.000236\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.950999\tLR: 0.000211\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 1.038010\tLR: 0.000186\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 1.114641\tLR: 0.000160\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.7005\n",
      "\n",
      "Sun Jun  5 11:27:30 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.931697\tLR: 0.000143\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.789587\tLR: 0.000118\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.984057\tLR: 0.000093\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.954184\tLR: 0.000068\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.853503\tLR: 0.000043\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.881701\tLR: 0.000018\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.6774, Average CER: 0.178882 Average WER: 0.5457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set, output_size=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mby39YVqZadd"
   },
   "source": [
    "### <b>Задание №1</b> (5 баллов):\n",
    "На данный момент практически все E2E SOTA решения используют [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Пример обучения BPE токенайзера можно найти в [link](https://github.com/google/sentencepiece/tree/master/python). Главное правильно обернуть его в наш класс TextTransformBPE. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JNbiW919e2le"
   },
   "outputs": [],
   "source": [
    "class TextTransformBPE:\n",
    "    def __init__(self, train_text, vocab_size=vocab_size):\n",
    "        \"\"\" Обучение BPE модели на 2000 юнитов\"\"\"\n",
    "        spm.SentencePieceTrainer.train('--input=' + train_text + ' --model_prefix=m --vocab_size=' + str(vocab_size))\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load('m.model')\n",
    "        \n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
    "        int_sequence = []\n",
    "        int_sequence = self.sp.encode_as_ids(text.upper())\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
    "        labels = list(map(int, labels))\n",
    "        string = self.sp.decode_ids(labels)\n",
    "        return string.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=train_clean_100_text_clean.txt --model_prefix=m --vocab_size=2000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_clean_100_text_clean.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: train_clean_100_text_clean.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 28539 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5298357\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9536% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999536\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 28539 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 80522 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 28539\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 33798\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 33798 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28243 obj=9.37547 num_tokens=59432 num_tokens/piece=2.10431\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21795 obj=7.60127 num_tokens=59764 num_tokens/piece=2.7421\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16342 obj=7.54919 num_tokens=64406 num_tokens/piece=3.94113\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=16337 obj=7.53067 num_tokens=64427 num_tokens/piece=3.94362\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12252 obj=7.62772 num_tokens=72733 num_tokens/piece=5.93642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12252 obj=7.60385 num_tokens=72728 num_tokens/piece=5.93601\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9189 obj=7.75535 num_tokens=81872 num_tokens/piece=8.90978\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9189 obj=7.72237 num_tokens=81864 num_tokens/piece=8.90891\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6891 obj=7.92348 num_tokens=90619 num_tokens/piece=13.1503\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6891 obj=7.88293 num_tokens=90624 num_tokens/piece=13.1511\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5168 obj=8.13299 num_tokens=99546 num_tokens/piece=19.262\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5168 obj=8.08573 num_tokens=99573 num_tokens/piece=19.2672\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3876 obj=8.36822 num_tokens=107089 num_tokens/piece=27.6287\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3876 obj=8.31648 num_tokens=107169 num_tokens/piece=27.6494\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2907 obj=8.63909 num_tokens=114502 num_tokens/piece=39.3884\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2907 obj=8.58131 num_tokens=114517 num_tokens/piece=39.3935\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2200 obj=8.92391 num_tokens=120773 num_tokens/piece=54.8968\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2200 obj=8.86619 num_tokens=120777 num_tokens/piece=54.8986\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "text_transform = TextTransformBPE('train_clean_100_text_clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=2001, bias=True)\n",
      ")\n",
      "Num Model Parameters 11546289\n",
      "Sun Jun  5 12:03:40 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 41.784515\tLR: 0.000040\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.336088\tLR: 0.000096\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.402687\tLR: 0.000152\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.198959\tLR: 0.000208\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.285443\tLR: 0.000264\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.032202\tLR: 0.000320\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.0149\n",
      "\n",
      "Sun Jun  5 12:08:49 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.127631\tLR: 0.000360\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 5.821997\tLR: 0.000416\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 5.427743\tLR: 0.000472\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.112283\tLR: 0.000528\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 5.072610\tLR: 0.000584\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 4.745228\tLR: 0.000640\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.4063\n",
      "\n",
      "Sun Jun  5 12:13:59 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 4.570737\tLR: 0.000680\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 4.504304\tLR: 0.000736\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 4.450552\tLR: 0.000792\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 4.221937\tLR: 0.000848\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 4.333843\tLR: 0.000904\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 4.366028\tLR: 0.000961\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.9264\n",
      "\n",
      "Sun Jun  5 12:19:09 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.240074\tLR: 0.001000\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 4.229813\tLR: 0.000975\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 4.463562\tLR: 0.000950\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 4.210570\tLR: 0.000925\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 4.131650\tLR: 0.000900\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 3.892884\tLR: 0.000875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.4284\n",
      "\n",
      "Sun Jun  5 12:24:19 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 4.015980\tLR: 0.000857\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 3.710799\tLR: 0.000832\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 3.686198\tLR: 0.000807\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 3.721479\tLR: 0.000782\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.767677\tLR: 0.000757\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 3.372141\tLR: 0.000732\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.8198, Average CER: 0.434893 Average WER: 0.6448\n",
      "\n",
      "Sun Jun  5 12:32:47 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.307498\tLR: 0.000714\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 3.274879\tLR: 0.000689\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.060057\tLR: 0.000664\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 2.898982\tLR: 0.000639\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 2.754812\tLR: 0.000614\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 2.925870\tLR: 0.000589\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.4627\n",
      "\n",
      "Sun Jun  5 12:37:57 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 3.175174\tLR: 0.000571\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 2.617022\tLR: 0.000546\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 2.844057\tLR: 0.000521\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 2.859176\tLR: 0.000496\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 2.796697\tLR: 0.000471\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 2.618916\tLR: 0.000446\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.2431\n",
      "\n",
      "Sun Jun  5 12:43:07 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.641377\tLR: 0.000428\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.619607\tLR: 0.000403\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.648883\tLR: 0.000378\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 2.709594\tLR: 0.000353\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.452452\tLR: 0.000328\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.442489\tLR: 0.000303\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.0707\n",
      "\n",
      "Sun Jun  5 12:48:17 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.731057\tLR: 0.000286\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.539116\tLR: 0.000261\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.325470\tLR: 0.000236\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.620144\tLR: 0.000211\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 2.537286\tLR: 0.000186\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 2.212840\tLR: 0.000160\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.9586\n",
      "\n",
      "Sun Jun  5 12:53:28 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.145477\tLR: 0.000143\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.235172\tLR: 0.000118\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.161199\tLR: 0.000093\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 2.500750\tLR: 0.000068\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.518723\tLR: 0.000043\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.420467\tLR: 0.000018\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.8969, Average CER: 0.278121 Average WER: 0.4803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set, output_size=vocab_size + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFS3PNxEAUiK"
   },
   "source": [
    "### **Ответ**:\n",
    "\n",
    "Обучение BPE модели позволило снизить WER с 0.5457 до 0.4803."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV48Q7HqZsAD"
   },
   "source": [
    "### <b>Задание №2</b> (5 баллов):\n",
    "Импровизация по улучшению качества распознавания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BPE c 4000 юнитами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=train_clean_100_text_clean.txt --model_prefix=m --vocab_size=4000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_clean_100_text_clean.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 4000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: train_clean_100_text_clean.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 28539 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5298357\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9536% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999536\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 28539 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 80522 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 28539\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 33798\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 33798 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28243 obj=9.37547 num_tokens=59432 num_tokens/piece=2.10431\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21795 obj=7.60127 num_tokens=59764 num_tokens/piece=2.7421\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16342 obj=7.54919 num_tokens=64406 num_tokens/piece=3.94113\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=16337 obj=7.53067 num_tokens=64427 num_tokens/piece=3.94362\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12252 obj=7.62772 num_tokens=72733 num_tokens/piece=5.93642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12252 obj=7.60385 num_tokens=72728 num_tokens/piece=5.93601\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9189 obj=7.75535 num_tokens=81872 num_tokens/piece=8.90978\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9189 obj=7.72237 num_tokens=81864 num_tokens/piece=8.90891\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6891 obj=7.92348 num_tokens=90619 num_tokens/piece=13.1503\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6891 obj=7.88293 num_tokens=90624 num_tokens/piece=13.1511\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5168 obj=8.13299 num_tokens=99546 num_tokens/piece=19.262\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5168 obj=8.08573 num_tokens=99573 num_tokens/piece=19.2672\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=4400 obj=8.23382 num_tokens=103991 num_tokens/piece=23.6343\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=4400 obj=8.20872 num_tokens=103985 num_tokens/piece=23.633\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4000\n",
    "text_transform = TextTransformBPE('train_clean_100_text_clean.txt', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=4001, bias=True)\n",
      ")\n",
      "Num Model Parameters 12188289\n",
      "Sun Jun  5 14:17:22 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 52.074368\tLR: 0.000040\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.503116\tLR: 0.000096\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.538324\tLR: 0.000152\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.732663\tLR: 0.000208\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.508296\tLR: 0.000264\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.628091\tLR: 0.000320\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.4274\n",
      "\n",
      "Sun Jun  5 14:22:40 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.288240\tLR: 0.000360\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 6.111539\tLR: 0.000416\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 5.953312\tLR: 0.000472\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.379038\tLR: 0.000528\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 5.401687\tLR: 0.000584\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 5.384206\tLR: 0.000640\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.6918\n",
      "\n",
      "Sun Jun  5 14:28:00 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 4.737537\tLR: 0.000680\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 4.788940\tLR: 0.000736\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 4.625396\tLR: 0.000792\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 4.632012\tLR: 0.000848\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 4.611275\tLR: 0.000904\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 4.501019\tLR: 0.000961\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.1666\n",
      "\n",
      "Sun Jun  5 14:33:20 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.521588\tLR: 0.001000\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 4.276813\tLR: 0.000975\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 4.176115\tLR: 0.000950\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 4.636485\tLR: 0.000925\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 4.092392\tLR: 0.000900\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 4.090141\tLR: 0.000875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.6795\n",
      "\n",
      "Sun Jun  5 14:38:40 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 4.019820\tLR: 0.000857\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 3.870274\tLR: 0.000832\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 4.189270\tLR: 0.000807\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 3.598940\tLR: 0.000782\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.691972\tLR: 0.000757\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 3.752898\tLR: 0.000732\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 3.0486, Average CER: 0.461245 Average WER: 0.6524\n",
      "\n",
      "Sun Jun  5 14:47:27 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.927814\tLR: 0.000714\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 3.526548\tLR: 0.000689\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.190047\tLR: 0.000664\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 3.443527\tLR: 0.000639\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 3.083987\tLR: 0.000614\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 2.877654\tLR: 0.000589\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.6405\n",
      "\n",
      "Sun Jun  5 14:52:46 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 2.863330\tLR: 0.000571\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 3.463774\tLR: 0.000546\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 2.749723\tLR: 0.000521\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 2.806169\tLR: 0.000496\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 3.132240\tLR: 0.000471\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 2.985846\tLR: 0.000446\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.3821\n",
      "\n",
      "Sun Jun  5 14:58:06 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.754210\tLR: 0.000428\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.483721\tLR: 0.000403\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.671264\tLR: 0.000378\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 2.414114\tLR: 0.000353\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.752263\tLR: 0.000328\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.741496\tLR: 0.000303\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.2400\n",
      "\n",
      "Sun Jun  5 15:03:25 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.566870\tLR: 0.000286\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.772423\tLR: 0.000261\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.337341\tLR: 0.000236\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.468799\tLR: 0.000211\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 2.415049\tLR: 0.000186\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 2.696675\tLR: 0.000160\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.1309\n",
      "\n",
      "Sun Jun  5 15:08:45 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.149631\tLR: 0.000143\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.137435\tLR: 0.000118\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.724653\tLR: 0.000093\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 2.636619\tLR: 0.000068\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.224023\tLR: 0.000043\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.497817\tLR: 0.000018\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.0782, Average CER: 0.304768 Average WER: 0.4810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set, output_size=vocab_size + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чуть хуже, чем на 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подкрутим параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к модели BPE c 2000 юнитами, увеличим число эпох до 15, увеличим начальны lr, поменяем стратегию в шедулере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=2,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\", output_size=29):\n",
    "    \n",
    "    blank_label = output_size - 1\n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": output_size,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=output_size-1, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='cos')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, blank_label=blank_label, decode=not(epoch % 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=train_clean_100_text_clean.txt --model_prefix=m --vocab_size=2000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_clean_100_text_clean.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: train_clean_100_text_clean.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 28539 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5298357\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9536% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999536\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 28539 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 80522 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 28539\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 33798\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 33798 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28243 obj=9.37547 num_tokens=59432 num_tokens/piece=2.10431\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21795 obj=7.60127 num_tokens=59764 num_tokens/piece=2.7421\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16342 obj=7.54919 num_tokens=64406 num_tokens/piece=3.94113\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=16337 obj=7.53067 num_tokens=64427 num_tokens/piece=3.94362\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12252 obj=7.62772 num_tokens=72733 num_tokens/piece=5.93642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12252 obj=7.60385 num_tokens=72728 num_tokens/piece=5.93601\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9189 obj=7.75535 num_tokens=81872 num_tokens/piece=8.90978\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9189 obj=7.72237 num_tokens=81864 num_tokens/piece=8.90891\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6891 obj=7.92348 num_tokens=90619 num_tokens/piece=13.1503\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6891 obj=7.88293 num_tokens=90624 num_tokens/piece=13.1511\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5168 obj=8.13299 num_tokens=99546 num_tokens/piece=19.262\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5168 obj=8.08573 num_tokens=99573 num_tokens/piece=19.2672\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3876 obj=8.36822 num_tokens=107089 num_tokens/piece=27.6287\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3876 obj=8.31648 num_tokens=107169 num_tokens/piece=27.6494\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2907 obj=8.63909 num_tokens=114502 num_tokens/piece=39.3884\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2907 obj=8.58131 num_tokens=114517 num_tokens/piece=39.3935\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2200 obj=8.92391 num_tokens=120773 num_tokens/piece=54.8968\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2200 obj=8.86619 num_tokens=120777 num_tokens/piece=54.8986\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 2000\n",
    "text_transform = TextTransformBPE('train_clean_100_text_clean.txt', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=2001, bias=True)\n",
      ")\n",
      "Num Model Parameters 11546289\n",
      "Mon Jun  6 09:09:35 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 41.784515\tLR: 0.000120\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.337883\tLR: 0.000131\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.403865\tLR: 0.000163\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.182682\tLR: 0.000216\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.241917\tLR: 0.000289\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 5.977083\tLR: 0.000381\n",
      "\n",
      "evaluating...\n",
      "Average loss: 5.8044\n",
      "\n",
      "Mon Jun  6 09:14:46 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 5.967058\tLR: 0.000457\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 5.639007\tLR: 0.000578\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 5.303379\tLR: 0.000714\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.039461\tLR: 0.000863\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 4.985763\tLR: 0.001022\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 4.602657\tLR: 0.001189\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.3047\n",
      "\n",
      "Mon Jun  6 09:19:57 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 4.527544\tLR: 0.001310\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 4.509150\tLR: 0.001485\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 4.325930\tLR: 0.001661\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 4.149873\tLR: 0.001836\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 4.316456\tLR: 0.002006\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 4.306070\tLR: 0.002170\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.8905\n",
      "\n",
      "Mon Jun  6 09:25:09 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.200105\tLR: 0.002281\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 4.221259\tLR: 0.002427\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 4.474081\tLR: 0.002561\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 4.259615\tLR: 0.002680\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 4.087924\tLR: 0.002782\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 3.861687\tLR: 0.002866\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.3730\n",
      "\n",
      "Mon Jun  6 09:30:20 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 4.013050\tLR: 0.002913\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 3.709584\tLR: 0.002963\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 3.866376\tLR: 0.002992\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 3.742469\tLR: 0.003000\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.815931\tLR: 0.002997\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 3.454118\tLR: 0.002990\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.8045, Average CER: 0.427270 Average WER: 0.6476\n",
      "\n",
      "Mon Jun  6 09:43:29 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.300681\tLR: 0.002983\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 3.411696\tLR: 0.002969\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.119835\tLR: 0.002952\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 2.966907\tLR: 0.002930\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 2.810665\tLR: 0.002904\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 3.077014\tLR: 0.002875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.4954\n",
      "\n",
      "Mon Jun  6 09:51:38 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 3.303333\tLR: 0.002851\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 2.742405\tLR: 0.002815\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 2.930292\tLR: 0.002776\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 2.958079\tLR: 0.002733\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 2.871317\tLR: 0.002686\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 2.724412\tLR: 0.002636\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.2840\n",
      "\n",
      "Mon Jun  6 09:56:49 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.744784\tLR: 0.002599\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.786333\tLR: 0.002544\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.894904\tLR: 0.002487\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 2.720226\tLR: 0.002426\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.588183\tLR: 0.002363\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.725098\tLR: 0.002297\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.1015\n",
      "\n",
      "Mon Jun  6 10:02:00 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.947503\tLR: 0.002250\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.650980\tLR: 0.002181\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.453233\tLR: 0.002110\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.700721\tLR: 0.002037\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.397706\tLR: 0.001756\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.145706\tLR: 0.001679\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 2.500973\tLR: 0.001600\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.661832\tLR: 0.001522\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.466222\tLR: 0.001443\n",
      "\n",
      "evaluating...\n",
      "Train Epoch: 11 [5000/28539 (18%)]\tLoss: 2.124801\tLR: 0.001309\n",
      "Train Epoch: 11 [10000/28539 (35%)]\tLoss: 2.074022\tLR: 0.001232\n",
      "Train Epoch: 11 [15000/28539 (53%)]\tLoss: 2.213994\tLR: 0.001155\n",
      "Train Epoch: 11 [20000/28539 (70%)]\tLoss: 2.349229\tLR: 0.001079\n",
      "Train Epoch: 11 [25000/28539 (88%)]\tLoss: 1.935280\tLR: 0.001004\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.6709\n",
      "\n",
      "Mon Jun  6 10:21:34 UTC 2022\n",
      "Train Epoch: 12 [0/28539 (0%)]\tLoss: 1.805993\tLR: 0.000952\n",
      "Train Epoch: 12 [5000/28539 (18%)]\tLoss: 1.927757\tLR: 0.000879\n",
      "Train Epoch: 12 [10000/28539 (35%)]\tLoss: 1.928887\tLR: 0.000809\n",
      "Train Epoch: 12 [15000/28539 (53%)]\tLoss: 1.881400\tLR: 0.000740\n",
      "Train Epoch: 12 [20000/28539 (70%)]\tLoss: 2.098969\tLR: 0.000673\n",
      "Train Epoch: 12 [25000/28539 (88%)]\tLoss: 1.797021\tLR: 0.000609\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.5818\n",
      "\n",
      "Mon Jun  6 10:26:45 UTC 2022\n",
      "Train Epoch: 13 [0/28539 (0%)]\tLoss: 1.786972\tLR: 0.000565\n",
      "Train Epoch: 13 [5000/28539 (18%)]\tLoss: 2.070649\tLR: 0.000504\n",
      "Train Epoch: 13 [10000/28539 (35%)]\tLoss: 1.861134\tLR: 0.000447\n",
      "Train Epoch: 13 [15000/28539 (53%)]\tLoss: 2.003978\tLR: 0.000392\n",
      "Train Epoch: 13 [20000/28539 (70%)]\tLoss: 1.713186\tLR: 0.000341\n",
      "Train Epoch: 13 [25000/28539 (88%)]\tLoss: 1.778102\tLR: 0.000293\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.5198\n",
      "\n",
      "Mon Jun  6 10:31:56 UTC 2022\n",
      "Train Epoch: 14 [0/28539 (0%)]\tLoss: 1.740229\tLR: 0.000260\n",
      "Train Epoch: 14 [5000/28539 (18%)]\tLoss: 1.859880\tLR: 0.000218\n",
      "Train Epoch: 14 [10000/28539 (35%)]\tLoss: 1.589529\tLR: 0.000179\n",
      "Train Epoch: 14 [15000/28539 (53%)]\tLoss: 1.789092\tLR: 0.000143\n",
      "Train Epoch: 14 [20000/28539 (70%)]\tLoss: 1.683966\tLR: 0.000112\n",
      "Train Epoch: 14 [25000/28539 (88%)]\tLoss: 1.746789\tLR: 0.000084\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.4915\n",
      "\n",
      "Mon Jun  6 10:37:07 UTC 2022\n",
      "Train Epoch: 15 [0/28539 (0%)]\tLoss: 1.559451\tLR: 0.000067\n",
      "Train Epoch: 15 [5000/28539 (18%)]\tLoss: 1.765144\tLR: 0.000045\n",
      "Train Epoch: 15 [10000/28539 (35%)]\tLoss: 2.019839\tLR: 0.000028\n",
      "Train Epoch: 15 [15000/28539 (53%)]\tLoss: 1.768301\tLR: 0.000015\n",
      "Train Epoch: 15 [20000/28539 (70%)]\tLoss: 1.810903\tLR: 0.000006\n",
      "Train Epoch: 15 [25000/28539 (88%)]\tLoss: 1.879387\tLR: 0.000001\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.4846, Average CER: 0.226449 Average WER: 0.4271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 15\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "main(learning_rate, batch_size, test_batch_size, epochs, \n",
    "     libri_train_set, libri_test_set, output_size=vocab_size + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1OBVhLgATV_"
   },
   "source": [
    "### **Ответ**:\n",
    "\n",
    "Значения WER:\n",
    "* Baseline: 0.5457\n",
    "* BPE (Задание 1): 0.4803\n",
    "* Импровизация (Задание 2, пункт 2): 0.4271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "asr_lab_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
